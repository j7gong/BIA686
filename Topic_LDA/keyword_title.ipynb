{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('len of total: ', 419)\n",
      "('len of total: ', 831)\n",
      "('len of total: ', 1214)\n",
      "('len of total: ', 1604)\n",
      "('len of total: ', 1966)\n",
      "('len of total: ', 2322)\n",
      "('len of total: ', 2704)\n",
      "('len of total: ', 3088)\n",
      "('len of total: ', 3469)\n",
      "('len of total: ', 3752)\n",
      "('len of total: ', 4122)\n",
      "('len of total: ', 4498)\n",
      "('len of total: ', 4765)\n",
      "('len of total: ', 5129)\n",
      "('len of total: ', 5482)\n",
      "('len of total: ', 5836)\n",
      "('len of total: ', 6164)\n",
      "('len of total: ', 6553)\n",
      "('len of total: ', 6881)\n",
      "('len of total: ', 7202)\n",
      "('len of total: ', 7564)\n",
      "('len of total: ', 7883)\n",
      "('len of total: ', 8248)\n",
      "('len of total: ', 8584)\n",
      "('len of total: ', 8933)\n",
      "('len of total: ', 9287)\n",
      "('len of total: ', 9639)\n",
      "('len of total: ', 9971)\n",
      "('len of total: ', 10291)\n",
      "('len of total: ', 10634)\n",
      "('len of total: ', 10947)\n",
      "('len of total: ', 11268)\n",
      "('len of total: ', 11593)\n",
      "('len of total: ', 11911)\n",
      "('len of total: ', 12234)\n",
      "('len of total: ', 12536)\n",
      "('len of total: ', 12838)\n",
      "('len of total: ', 13141)\n",
      "('len of total: ', 13403)\n",
      "('len of total: ', 13581)\n",
      "('len of total: ', 13626)\n",
      "('len of total: ', 14015)\n",
      "('len of total: ', 14384)\n",
      "('len of total: ', 14763)\n",
      "('len of total: ', 15124)\n",
      "('len of total: ', 15475)\n",
      "('len of total: ', 15827)\n",
      "('len of total: ', 16168)\n",
      "('len of total: ', 16517)\n",
      "('len of total: ', 16850)\n",
      "('len of total: ', 17158)\n",
      "('len of total: ', 17514)\n",
      "('len of total: ', 17902)\n",
      "('len of total: ', 18262)\n",
      "('len of total: ', 18621)\n",
      "('len of total: ', 18890)\n",
      "('len of total: ', 19128)\n",
      "('len of total: ', 19503)\n",
      "('len of total: ', 19884)\n",
      "('len of total: ', 20242)\n",
      "('len of total: ', 20421)\n",
      "('len of total: ', 20735)\n",
      "('len of total: ', 21080)\n",
      "('len of total: ', 21440)\n",
      "('len of total: ', 21725)\n",
      "('len of total: ', 21999)\n",
      "('len of total: ', 22354)\n",
      "('len of total: ', 22717)\n",
      "('len of total: ', 22953)\n",
      "('len of total: ', 23283)\n",
      "('len of total: ', 23640)\n",
      "('len of total: ', 23888)\n",
      "('len of total: ', 24230)\n",
      "('len of total: ', 24560)\n",
      "('len of total: ', 24837)\n",
      "('len of total: ', 25177)\n",
      "('len of total: ', 25451)\n",
      "('len of total: ', 25792)\n",
      "('len of total: ', 26063)\n",
      "('len of total: ', 26366)\n",
      "('len of total: ', 26645)\n",
      "('len of total: ', 26942)\n",
      "('len of total: ', 27249)\n",
      "('len of total: ', 27547)\n",
      "('len of total: ', 27806)\n",
      "('len of total: ', 28039)\n",
      "('len of total: ', 28211)\n",
      "('len of total: ', 28256)\n",
      "fire retardancy; thermal analysis; thermal properties; biomaterial. preparation of a novel agar sodium alginate fire-retardancy film\n",
      "bone marrow derived mesenchymal stem cells; cell-derived matrix; alginate; chondrogenesis; osteogenesis; fibroblast-derived ecm. the three dimensional cues-integrated-biomaterial potentiates differentiation of human mesenchymal stem cells\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "# import string\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "def openfile(path):\n",
    "    f=open(path)\n",
    "    text=f.read()\n",
    "    f.close() \n",
    "    all_articles=text.split(\"\\n\\n\")\n",
    "#     print((\"len of article: \",len(all_articles)))\n",
    "    return all_articles\n",
    "\n",
    "\n",
    "\n",
    "def get_key_abs(all_articles,keywords_abstracts):\n",
    "    for art in all_articles:\n",
    "        if (\"\\nDE \" in art) and (\"\\nTI \" in art) and (\"\\nID \" in art):\n",
    "            DEs = re.findall(r'\\sDE[ ].*[\\s\\w;-]*\\sID', art)\n",
    "            TIs = re.findall(r'\\sTI[ ].*[\\s\\w:\\-]+', art)\n",
    "            if len(DEs)==1 and len(TIs)==1:\n",
    "                sentence = \"\"\n",
    "                for DE in DEs:\n",
    "                    DE=DE.split(\"ID\")[0]\n",
    "                    DE=DE.split(\"DE\")[1].strip().lower()\n",
    "                    DE=re.sub(r\"\\s+\", ' ',DE)\n",
    "                    sentence = sentence + DE + \". \"\n",
    "                for TI in TIs:\n",
    "                    TI=TI.split(\"SO\")[0]\n",
    "                    TI=TI.split(\"TI\")[1].strip().lower()\n",
    "                    TI=re.sub(r\"\\s+\", ' ',TI)\n",
    "                    sentence = sentence + TI\n",
    "                    sentence=re.sub('[^a-zA-Z;.,-]',' ',sentence)\n",
    "                    sentence=re.sub('\\s+',' ',sentence)                \n",
    "                keywords_abstracts.append(sentence)\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keywords_abstracts = []\n",
    "    \n",
    "    for i in range(1,42):\n",
    "        path = \"../data/biomaterial/savedrecs%d.txt\"%i\n",
    "        all_articles = openfile(path)\n",
    "        get_key_abs(all_articles,keywords_abstracts)\n",
    "        print((\"len of total: \",len(keywords_abstracts)))\n",
    "        \n",
    "    for i in range(1,48):\n",
    "        path = \"../data/biomedical_material/savedrecs%d.txt\"%i\n",
    "        all_articles = openfile(path)\n",
    "        get_key_abs(all_articles,keywords_abstracts)\n",
    "        print((\"len of total: \",len(keywords_abstracts)))\n",
    "    \n",
    "print(keywords_abstracts[0])\n",
    "print(keywords_abstracts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protein', 'proteins', 'prototyping', 'pseudomonas', 'pulp', 'pulsed', 'pure', 'purification', 'pva', 'quality']\n",
      "(28256, 1341)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LDA can only use raw term counts for LDA \n",
    "tf_vectorizer = CountVectorizer(max_df=0.90, \\\n",
    "                min_df=50, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(keywords_abstracts)\n",
    "\n",
    "# each feature is a word (bag of words)\n",
    "# get_feature_names() gives all words\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print(tf_feature_names[1000:1010])\n",
    "print(tf.shape)\n",
    "# print(tf)\n",
    "\n",
    "# split dataset into train (90%) and test sets (10%)\n",
    "# the test sets will be used to evaluate proplexity of topic modeling\n",
    "X_train, X_test = train_test_split(\\\n",
    "                tf, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 12, perplexity: 965.4748\n",
      "iteration: 2 of max_iter: 12, perplexity: 711.6839\n",
      "iteration: 3 of max_iter: 12, perplexity: 591.1724\n",
      "iteration: 4 of max_iter: 12, perplexity: 533.4799\n",
      "iteration: 5 of max_iter: 12, perplexity: 503.8434\n",
      "iteration: 6 of max_iter: 12, perplexity: 486.4711\n",
      "iteration: 7 of max_iter: 12, perplexity: 475.7665\n",
      "iteration: 8 of max_iter: 12, perplexity: 469.1166\n",
      "iteration: 9 of max_iter: 12, perplexity: 464.7383\n",
      "iteration: 10 of max_iter: 12, perplexity: 461.9114\n",
      "iteration: 11 of max_iter: 12, perplexity: 460.1442\n",
      "iteration: 12 of max_iter: 12, perplexity: 459.0391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "num_topics = 24            # how to estimate the num of topic?\n",
    "\n",
    "# Run LDA. For details, check\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#sklearn.decomposition.LatentDirichletAllocation.perplexity\n",
    "\n",
    "# max_iter control the number of iterations \n",
    "# evaluate_every determines how often the perplexity is calculated\n",
    "# n_jobs is the number of parallel threads\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, \\\n",
    "                                max_iter=12,verbose=1,\n",
    "                                evaluate_every=1, n_jobs=1,\n",
    "                                random_state=0).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['laser', 'corrosion', 'magnesium', 'coating', 'alloy', 'steel', 'stainless', 'mg', 'polyurethane', 'electrochemical']\n",
      "\n",
      "Topic 1:\n",
      "['tissue', 'engineering', 'scaffolds', 'scaffold', 'matrix', 'regeneration', 'biomaterial', 'biomaterials', 'extracellular', 'medicine']\n",
      "\n",
      "Topic 2:\n",
      "['materials', 'biomedical', 'review', 'porous', 'design', 'applications', 'material', 'printing', 'based', 'manufacturing']\n",
      "\n",
      "Topic 3:\n",
      "['plasma', 'adsorption', 'deposition', 'coatings', 'polyethylene', 'grafting', 'metal', 'biomaterial', 'gamma', 'albumin']\n",
      "\n",
      "Topic 4:\n",
      "['hydroxyapatite', 'synthesis', 'organic', 'characterization', 'composite', 'quantum', 'microwave', 'inorganic', 'solid', 'method']\n",
      "\n",
      "Topic 5:\n",
      "['surface', 'modification', 'protein', 'surfaces', 'blood', 'plasma', 'adsorption', 'compatibility', 'biomaterial', 'titanium']\n",
      "\n",
      "Topic 6:\n",
      "['shape', 'memory', 'nerve', 'analysis', 'element', 'finite', 'pressure', 'modeling', 'non', 'model']\n",
      "\n",
      "Topic 7:\n",
      "['chitosan', 'wound', 'healing', 'gelatin', 'alginate', 'hydrogel', 'membrane', 'cross', 'dressing', 'biomaterial']\n",
      "\n",
      "Topic 8:\n",
      "['microscopy', 'spectroscopy', 'force', 'electron', 'raman', 'atomic', 'oxygen', 'cancer', 'stress', 'analysis']\n",
      "\n",
      "Topic 9:\n",
      "['bone', 'calcium', 'phosphate', 'hydroxyapatite', 'biomaterial', 'regeneration', 'study', 'implant', 'cement', 'graft']\n",
      "\n",
      "Topic 10:\n",
      "['nanoparticles', 'magnetic', 'oxide', 'graphene', 'silica', 'nanoparticle', 'applications', 'iron', 'gold', 'nanomaterials']\n",
      "\n",
      "Topic 11:\n",
      "['cells', 'stem', 'cell', 'mesenchymal', 'human', 'differentiation', 'derived', 'cartilage', 'neural', 'osteogenic']\n",
      "\n",
      "Topic 12:\n",
      "['silk', 'cellulose', 'fibroin', 'electrospinning', 'nanofibers', 'electrospun', 'bacterial', 'fibers', 'nanofiber', 'fiber']\n",
      "\n",
      "Topic 13:\n",
      "['cell', 'adhesion', 'cells', 'response', 'culture', 'biomaterial', 'endothelial', 'biomaterials', 'proliferation', 'macrophage']\n",
      "\n",
      "Topic 14:\n",
      "['titanium', 'ti', 'alloy', 'alloys', 'al', 'biomedical', 'mechanical', 'properties', 'wear', 'nb']\n",
      "\n",
      "Topic 15:\n",
      "['antibacterial', 'activity', 'silver', 'nanoparticles', 'antimicrobial', 'ray', 'size', 'electron', 'synthesis', 'ag']\n",
      "\n",
      "Topic 16:\n",
      "['poly', 'acid', 'degradation', 'biodegradable', 'hyaluronic', 'lactic', 'vinyl', 'ethylene', 'based', 'synthesis']\n",
      "\n",
      "Topic 17:\n",
      "['adhesion', 'bacterial', 'biofilm', 'biomaterial', 'artificial', 'infection', 'diamond', 'anti', 'like', 'staphylococcus']\n",
      "\n",
      "Topic 18:\n",
      "['collagen', 'growth', 'bone', 'factor', 'vivo', 'vitro', 'protein', 'human', 'osteoblast', 'biomaterial']\n",
      "\n",
      "Topic 19:\n",
      "['biomedical', 'applications', 'glass', 'bioactive', 'gel', 'sol', 'medical', 'bioactivity', 'natural', 'materials']\n",
      "\n",
      "Topic 20:\n",
      "['polymer', 'hydrogels', 'polymers', 'hydrogel', 'responsive', 'based', 'materials', 'ph', 'injectable', 'stimuli']\n",
      "\n",
      "Topic 21:\n",
      "['imaging', 'biomedical', 'high', 'optical', 'analysis', 'micro', 'research', 'ion', 'fluid', 'liquid']\n",
      "\n",
      "Topic 22:\n",
      "['delivery', 'drug', 'release', 'self', 'controlled', 'assembly', 'layer', 'systems', 'gene', 'peptide']\n",
      "\n",
      "Topic 23:\n",
      "['properties', 'mechanical', 'carbon', 'nanotubes', 'composites', 'thermal', 'composite', 'structure', 'property', 'nanotube']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_top_words=10\n",
    "\n",
    "# lda.components_ returns a KxN matrix\n",
    "# for word distribution in each topic.\n",
    "# Each row consists of \n",
    "# probability (counts) of each word in the feature space\n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print (\"Topic %d:\" % (topic_idx))\n",
    "    # print out top 20 words per topic \n",
    "    words=[tf_feature_names[i] for i in topic.argsort()[::-1][0:num_top_words]]\n",
    "    print(words)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
